# ArXiv Digest Configuration

# Output Settings
output:
  base_dir: "./data" # Base directory for output files

# Paper Fetching Settings
arxiv:
  # Categories can be found at https://arxiv.org/category_taxonomy
  categories:
    # Compute Science Categories
    - "cs.AI" # Artificial Intelligence
    - "cs.CL" # Computation and Language
    - "cs.CV" # Computer Vision
    - "cs.LG" # Machine Learning
    - "cs.GL" # General Computer Science
    - "cs.HC" # Human-Computer Interaction
    - "cs.MA" # Multiagent Systems
    - "cs.NE" # Neural and Evolutionary Computing

    # Statistics Categories
    - "stat.AP" # Applications (Statistics)
    - "stat.CO" # Computation (Statistics)
    - "stat.ME" # Methodology (Statistics)
    - "stat.ML" # Machine Learning (Statistics)
    - "stat.OT" # Other (Statistics)
    - "stat.TH" # Theory (Statistics)

    # Physics Categories
    - "astro-ph.CO" # Cosmology and Nongalactic Astrophysics
    - "astro-ph.EP" # Earth and Planetary Astrophysics
    - "astro-ph.GA" # General Astrophysics
    - "astro-ph.HE" # High Energy Astrophysical Phenomena
    - "astro-ph.IM" # Instrumentation and Methods for Astrophysics
    - "astro-ph.SR" # Solar and Stellar Astrophysics
    - "cond-mat.dis-nn" # Statistical Mechanics (Condensed Matter)
    - "physics.data-an" # Data Analysis, Statistics and Probability (Physics)
    - "physics.ed-ph" # Education (Physics)
    - "physics.gen-ph" # General Physics
    - "physics.geo-ph" # Geophysics
    - "physics.space-ph" # Space Physics

  days_back: 1 # Days to look back for recent papers
  arxiv_days_only: true # If true, automatically shift search window if no papers found
  max_papers_per_category: 200 # Maximum papers to fetch per category
  filter_legacy_categories: true # Remove legacy categories from papers
  require_modern_categories: true # Exclude papers with only legacy categories
  request_delay: 1.0 # Rate limiting between API calls

# LLM-based Paper Scoring Settings
scoring:
  # Input file (null = auto-detect most recent arxiv_papers_*.json/csv)
  input_file: null

  # Model configuration (must be defined in config/llm.yaml)
  model_alias: "deepseek-r1-qwen3"

  # Limit number of papers to score (null = score all papers)
  # Note: Papers are selected in order from arxiv fetch (first N papers)
  max_papers: null

  # Batch size for scoring (number of papers per LLM request, null = single paper per request)
  batch_size: 3

  # Retry configuration
  retry_attempts: 2

  # Metadata fields to include when scoring papers
  # Available: title, abstract, authors, categories, published, updated
  include_metadata:
    - title
    - abstract
    # - authors      # Uncomment to include author information
    # - categories   # Uncomment to include arXiv categories

  # Three-part prompt configuration for scoring
  # Part 1: Research context - describe the researcher's background and interests
  research_context_prompt: |
    You are evaluating research papers for Josh Speagle, an Assistant Professor of 
    Astrostatistics at the University of Toronto whose research motto is "Statistical AI 
    for Cosmic Discovery." His research focuses on four core areas:

    1. **Statistical Learning & AI**: Novel methods to discover patterns from large, messy datasets
    2. **Interpretability & Insight**: Rigorous understanding of methods to extract scientific insights
    3. **Inference & Computation**: Robust frameworks and algorithms to quantify what we can learn from data
    4. **Discovery & Understanding**: Applying methods to astronomical surveys to understand galaxy formation and evolution

    Josh values work that advances theoretical understanding of machine learning and statistics,
    introduces novel methodological approaches, demonstrates innovative scientific applications,
    announces significant observational/experimental results, and has potential to influence
    future research in ML/statistics, especially in astrophysics contexts.

  # Part 2: Scoring strategy - define what criteria to use for scoring
  scoring_strategy_prompt: |
    Evaluate papers using this three-component framework:

    **1. RELEVANCE (40% weight):**
    - Direct connection to astrophysics, AI/ML/statistics, or computational methods
    - Alignment with astrostatistics, interpretable AI, Bayesian methods, uncertainty quantification, or scientific applications
    - Cross-disciplinary potential bridging stats/astro/CS

    **2. CONTRIBUTION (30% weight):**
    - Novel techniques or significant improvements to existing methods
    - Theoretical rigor and mathematical soundness
    - Reproducibility, validation, and innovative AI/ML/statistics applications
    - Provides pedagogical insights that can be leveraged for students/training programs

    **3. IMPACT (30% weight):**
    - Directly applicable to current projects/surveys/challenges
    - Establishes foundations for follow-up work or expected to be heavily cited
    - Solves limiting problems or opens unexplored directions

  # Part 3: Score calculation - define numerical scale for scores
  score_calculation_prompt: |
    Rate each component from 1-10:
    - Relevance score (1-10): ___
    - Contribution score (1-10): ___
    - Impact score (1-10): ___

    Calculate: Final Score = (Relevance × 0.4) + (Contribution × 0.3) + (Impact × 0.3)
    Round to one decimal place.

    Be decisive about scores. Make sure to use the full scoring range effectively for each component.
    Scores should be calibrated so that a typical paper scores a 3 in each component
    (most papers are not directly relevant, make minor contributions, and have limited impact).
    Strong papers should score above a 7 in at least one component, with a final score above 5.
    Exceptional papers should score above 8 in at least two components, with a final score above 7.

# PDF Processing Settings
pdf_processing:
  # Input file (null = auto-detect most recent arxiv_papers_*_scored.json/csv)
  input_file: null

  # Paper Selection Configuration
  selection:
    # Percentile-based selection: top X% of papers by score
    percentile: 20

    # Score threshold: papers must also meet minimum score requirement
    score_threshold: 7.0

    # Quantity constraints: ensure reasonable number of papers
    min_papers: 5
    max_papers: 25

    # Random paper addition for exploration/serendipity
    # Add n_random papers from those not included in the original selection (0 = no random addition)
    # Sampling is based on softmax(scores / temperature) difference of 1 is a factor of e in odds
    # Temperature controls randomness: 0 = deterministic (top-N), 1 = score-based, null = uniform
    n_random: 5
    temperature: 1.0
    random_seed: null # null = random seed; only set if you want reproducibility for testing

  # PDF Download Configuration
  download:
    # Rate limiting (arXiv recommends delays between requests)
    rate_limit_delay: 3.0 # Seconds between downloads
    max_retries: 3 # Number of retry attempts for failed downloads
    timeout: 30 # Timeout in seconds for each download

    # Storage settings
    storage_dir: "./data/pdfs" # Directory to store downloaded PDFs
    organize_by_date: true # Organize PDFs in date-based subdirectories

    # File naming
    filename_format: "{arxiv_id}_{title_slug}.pdf" # Filename pattern
    max_filename_length: 100 # Maximum filename length (excluding extension)

    # Download verification
    verify_downloads: true # Verify PDF file integrity after download
    min_file_size: 10000 # Minimum file size in bytes (10KB)

  # PDF Text Extraction Configuration
  extraction:
    # Extraction method selection
    method: "auto" # auto, pdfplumber, pymupdf, pypdf2, none (no extraction)
    fallback_methods: ["pymupdf", "pypdf2", "pdfplumber"] # Try these if primary fails

    # Content extraction options
    extract_text: true # Extract text content

    # Text processing options
    preserve_formatting: false # Keep original formatting vs. clean text
    remove_headers_footers: true # Remove page headers/footers
    min_text_length: 1000 # Minimum characters for valid extraction

    # Quality filtering
    max_extraction_errors: 5 # Skip papers with too many extraction errors
    require_abstract_keywords: true # Verify extraction quality using known abstracts

    # Output format for extracted text
    text_format: "plain" # plain, markdown, json
    include_metadata: true # Include extraction metadata in output

    # Storage options for extracted content
    save_extracted_text: true # Save extracted text to files
    text_storage_dir: "./data/extracted_text" # Directory for text files (mirrors PDF structure)
    cleanup_pdfs_after_extraction: true # Delete PDFs after successful extraction (ignored if none)
